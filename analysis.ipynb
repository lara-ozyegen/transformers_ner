{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Load multiclass classification report\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(fold_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass_classification_report.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 36\u001b[0m     multiclass_report \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m multiclass_metrics\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m multiclass_metrics[category]\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# This is the base directory where your fold reports are located.\n",
    "base_dir = 'analysis/phee/reports'  # Replace with your actual path\n",
    "\n",
    "# Initialize dictionaries to hold all the metric values from each fold.\n",
    "binary_metrics = {\n",
    "    'O': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'I': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'macro avg': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'weighted avg': {'precision': [], 'recall': [], 'f1-score': []}\n",
    "}\n",
    "\n",
    "multiclass_metrics = {\n",
    "    \"macro avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"weighted avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"macro_wo_O\": {'precision': [], 'recall': [], 'f1-score': []}\n",
    "\n",
    "}\n",
    "\n",
    "# Process each fold\n",
    "for fold in range(5):\n",
    "    fold_dir = os.path.join(base_dir, f'fold{fold}')\n",
    "\n",
    "    # Load binary classification report\n",
    "    with open(os.path.join(fold_dir, 'binary_classification_report.json'), 'r') as f:\n",
    "        binary_report = json.load(f)\n",
    "        for category in binary_metrics.keys():\n",
    "            for metric in binary_metrics[category].keys():\n",
    "                binary_metrics[category][metric].append(binary_report[category][metric])\n",
    "\n",
    "    # Load multiclass classification report\n",
    "    with open(os.path.join(fold_dir, 'multiclass_classification_report.json'), 'r') as f:\n",
    "        multiclass_report = json.load(f).T\n",
    "        for category in multiclass_metrics.keys():\n",
    "            for metric in multiclass_metrics[category].keys():\n",
    "                multiclass_metrics[category][metric].append(multiclass_report[category][metric])\n",
    "\n",
    "# Calculate mean and standard deviation for binary metrics\n",
    "binary_results = {}\n",
    "for category, metrics in binary_metrics.items():\n",
    " \n",
    "    binary_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        binary_results[category][metric] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values)\n",
    "        }\n",
    "\n",
    "# Do the same for multiclass metrics\n",
    "multiclass_results = {}\n",
    "for category, metrics in multiclass_metrics.items():\n",
    "    multiclass_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        multiclass_results[category][metric] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values)\n",
    "        }\n",
    "\n",
    "# Now you have binary_results and multiclass_results with the mean and std dev of each metric.\n",
    "print('Binary results:')    \n",
    "print(binary_results)\n",
    "print('Multiclass results:')\n",
    "print(multiclass_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh-crf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
