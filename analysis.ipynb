{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-Background': {'precision': 0.91, 'recall': 0.746, 'f1-score': 0.8200000000000001, 'support': 776.0}, 'I-Other': {'precision': 0.7030000000000001, 'recall': 0.759, 'f1-score': 0.73, 'support': 274.0}, 'I-Problem': {'precision': 0.872, 'recall': 0.887, 'f1-score': 0.879, 'support': 3889.0}, 'I-Test': {'precision': 0.5700000000000001, 'recall': 0.506, 'f1-score': 0.536, 'support': 160.0}, 'I-Treatment': {'precision': 0.833, 'recall': 0.89, 'f1-score': 0.86, 'support': 2680.0}, 'O': {'precision': 0.9380000000000001, 'recall': 0.929, 'f1-score': 0.933, 'support': 12477.0}, 'accuracy': {'precision': 0.903, 'recall': 0.903, 'f1-score': 0.903, 'support': 0.903}, 'macro avg': {'precision': 0.804, 'recall': 0.786, 'f1-score': 0.793, 'support': 20256.0}, 'weighted avg': {'precision': 0.904, 'recall': 0.903, 'f1-score': 0.903, 'support': 20256.0}, 'macro_wo_O': {'precision': 0.778, 'recall': 0.758, 'f1-score': 0.765, 'support': 7779.0}}\n",
      "{'I-Background': {'precision': 0.854, 'recall': 0.724, 'f1-score': 0.784, 'support': 863.0}, 'I-Other': {'precision': 0.6920000000000001, 'recall': 0.791, 'f1-score': 0.738, 'support': 273.0}, 'I-Problem': {'precision': 0.867, 'recall': 0.904, 'f1-score': 0.885, 'support': 3749.0}, 'I-Test': {'precision': 0.681, 'recall': 0.665, 'f1-score': 0.673, 'support': 209.0}, 'I-Treatment': {'precision': 0.8130000000000001, 'recall': 0.857, 'f1-score': 0.834, 'support': 2648.0}, 'O': {'precision': 0.934, 'recall': 0.919, 'f1-score': 0.926, 'support': 12813.0}, 'accuracy': {'precision': 0.896, 'recall': 0.896, 'f1-score': 0.896, 'support': 0.896}, 'macro avg': {'precision': 0.807, 'recall': 0.81, 'f1-score': 0.807, 'support': 20555.0}, 'weighted avg': {'precision': 0.897, 'recall': 0.896, 'f1-score': 0.896, 'support': 20555.0}, 'macro_wo_O': {'precision': 0.781, 'recall': 0.788, 'f1-score': 0.783, 'support': 7742.0}}\n",
      "{'I-Background': {'precision': 0.866, 'recall': 0.797, 'f1-score': 0.8300000000000001, 'support': 970.0}, 'I-Other': {'precision': 0.659, 'recall': 0.796, 'f1-score': 0.721, 'support': 240.0}, 'I-Problem': {'precision': 0.88, 'recall': 0.901, 'f1-score': 0.89, 'support': 3923.0}, 'I-Test': {'precision': 0.641, 'recall': 0.549, 'f1-score': 0.592, 'support': 182.0}, 'I-Treatment': {'precision': 0.85, 'recall': 0.853, 'f1-score': 0.852, 'support': 2830.0}, 'O': {'precision': 0.937, 'recall': 0.933, 'f1-score': 0.935, 'support': 13106.0}, 'accuracy': {'precision': 0.906, 'recall': 0.906, 'f1-score': 0.906, 'support': 0.906}, 'macro avg': {'precision': 0.805, 'recall': 0.805, 'f1-score': 0.803, 'support': 21251.0}, 'weighted avg': {'precision': 0.906, 'recall': 0.906, 'f1-score': 0.906, 'support': 21251.0}, 'macro_wo_O': {'precision': 0.779, 'recall': 0.779, 'f1-score': 0.777, 'support': 8145.0}}\n",
      "{'I-Background': {'precision': 0.848, 'recall': 0.799, 'f1-score': 0.8230000000000001, 'support': 806.0}, 'I-Other': {'precision': 0.725, 'recall': 0.772, 'f1-score': 0.748, 'support': 267.0}, 'I-Problem': {'precision': 0.885, 'recall': 0.889, 'f1-score': 0.887, 'support': 3845.0}, 'I-Test': {'precision': 0.747, 'recall': 0.654, 'f1-score': 0.6970000000000001, 'support': 185.0}, 'I-Treatment': {'precision': 0.833, 'recall': 0.858, 'f1-score': 0.845, 'support': 2551.0}, 'O': {'precision': 0.9390000000000001, 'recall': 0.936, 'f1-score': 0.937, 'support': 12950.0}, 'accuracy': {'precision': 0.907, 'recall': 0.907, 'f1-score': 0.907, 'support': 0.907}, 'macro avg': {'precision': 0.8300000000000001, 'recall': 0.8180000000000001, 'f1-score': 0.8230000000000001, 'support': 20604.0}, 'weighted avg': {'precision': 0.908, 'recall': 0.907, 'f1-score': 0.907, 'support': 20604.0}, 'macro_wo_O': {'precision': 0.808, 'recall': 0.794, 'f1-score': 0.8, 'support': 7654.0}}\n",
      "{'I-Background': {'precision': 0.849, 'recall': 0.778, 'f1-score': 0.812, 'support': 807.0}, 'I-Other': {'precision': 0.592, 'recall': 0.787, 'f1-score': 0.676, 'support': 221.0}, 'I-Problem': {'precision': 0.87, 'recall': 0.903, 'f1-score': 0.886, 'support': 3861.0}, 'I-Test': {'precision': 0.621, 'recall': 0.536, 'f1-score': 0.5750000000000001, 'support': 196.0}, 'I-Treatment': {'precision': 0.833, 'recall': 0.858, 'f1-score': 0.845, 'support': 2670.0}, 'O': {'precision': 0.9410000000000001, 'recall': 0.926, 'f1-score': 0.933, 'support': 12805.0}, 'accuracy': {'precision': 0.902, 'recall': 0.902, 'f1-score': 0.902, 'support': 0.902}, 'macro avg': {'precision': 0.784, 'recall': 0.798, 'f1-score': 0.788, 'support': 20560.0}, 'weighted avg': {'precision': 0.903, 'recall': 0.902, 'f1-score': 0.902, 'support': 20560.0}, 'macro_wo_O': {'precision': 0.753, 'recall': 0.772, 'f1-score': 0.759, 'support': 7755.0}}\n",
      "Binary results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>{'mean': 0.938, 'std': 0.002}</td>\n",
       "      <td>{'mean': 0.929, 'std': 0.006}</td>\n",
       "      <td>{'mean': 0.933, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>{'mean': 0.885, 'std': 0.009}</td>\n",
       "      <td>{'mean': 0.899, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.892, 'std': 0.006}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.911, 'std': 0.005}</td>\n",
       "      <td>{'mean': 0.914, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.912, 'std': 0.005}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.918, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.917, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.917, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "O             {'mean': 0.938, 'std': 0.002}  {'mean': 0.929, 'std': 0.006}   \n",
       "I             {'mean': 0.885, 'std': 0.009}  {'mean': 0.899, 'std': 0.004}   \n",
       "macro avg     {'mean': 0.911, 'std': 0.005}  {'mean': 0.914, 'std': 0.004}   \n",
       "weighted avg  {'mean': 0.918, 'std': 0.004}  {'mean': 0.917, 'std': 0.004}   \n",
       "\n",
       "                                   f1-score  \n",
       "O             {'mean': 0.933, 'std': 0.004}  \n",
       "I             {'mean': 0.892, 'std': 0.006}  \n",
       "macro avg     {'mean': 0.912, 'std': 0.005}  \n",
       "weighted avg  {'mean': 0.917, 'std': 0.004}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# This is the base directory where your fold reports are located.\n",
    "base_dir = 'analysis/phee/reports'  # Replace with your actual path\n",
    "\n",
    "# Initialize dictionaries to hold all the metric values from each fold.\n",
    "binary_metrics = {\n",
    "    'O': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'I': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'macro avg': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'weighted avg': {'precision': [], 'recall': [], 'f1-score': []}\n",
    "}\n",
    "\n",
    "multiclass_metrics = {\n",
    "    \"macro avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"weighted avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"macro_wo_O\": {'precision': [], 'recall': [], 'f1-score': []}\n",
    "\n",
    "}\n",
    "\n",
    "# Process each fold\n",
    "for fold in range(5):\n",
    "    fold_dir = os.path.join(base_dir, f'fold{fold}')\n",
    "\n",
    "    # Load binary classification report\n",
    "    with open(os.path.join(fold_dir, 'binary_classification_report.json'), 'r') as f:\n",
    "        binary_report = json.load(f)\n",
    "        for category in binary_metrics.keys():\n",
    "            for metric in binary_metrics[category].keys():\n",
    "                binary_metrics[category][metric].append(binary_report[category][metric])\n",
    "\n",
    "    # Load multiclass classification report\n",
    "    multi_df = pd.read_json(os.path.join(fold_dir, 'multiclass_classification_report.json'))\n",
    "  \n",
    "    # with open(os.path.join(fold_dir, 'multiclass_classification_report.json'), 'r') as f:\n",
    "    multiclass_report = multi_df.T.to_dict()\n",
    "    print(multiclass_report)\n",
    "\n",
    "    for category in multiclass_metrics.keys():\n",
    "\n",
    "        for metric in multiclass_metrics[category].keys():\n",
    "            multiclass_metrics[category][metric].append(multiclass_report[category][metric])\n",
    "\n",
    "# Calculate mean and standard deviation for binary metrics\n",
    "binary_results = {}\n",
    "for category, metrics in binary_metrics.items():\n",
    " \n",
    "    binary_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        binary_results[category][metric] = {\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Do the same for multiclass metrics\n",
    "multiclass_results = {}\n",
    "for category, metrics in multiclass_metrics.items():\n",
    "    multiclass_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        multiclass_results[category][metric] = {\n",
    "            # round to 3 decimal places\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Now you have binary_results and multiclass_results with the mean and std dev of each metric.\n",
    "print('Binary results:')\n",
    "# dict to dataframe\n",
    "binary_results = pd.DataFrame(binary_results)    \n",
    "binary_results.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.806, 'std': 0.015}</td>\n",
       "      <td>{'mean': 0.803, 'std': 0.011}</td>\n",
       "      <td>{'mean': 0.803, 'std': 0.012}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.904, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.903, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.903, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_wo_O</th>\n",
       "      <td>{'mean': 0.78, 'std': 0.017}</td>\n",
       "      <td>{'mean': 0.778, 'std': 0.013}</td>\n",
       "      <td>{'mean': 0.777, 'std': 0.014}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "macro avg     {'mean': 0.806, 'std': 0.015}  {'mean': 0.803, 'std': 0.011}   \n",
       "weighted avg  {'mean': 0.904, 'std': 0.004}  {'mean': 0.903, 'std': 0.004}   \n",
       "macro_wo_O     {'mean': 0.78, 'std': 0.017}  {'mean': 0.778, 'std': 0.013}   \n",
       "\n",
       "                                   f1-score  \n",
       "macro avg     {'mean': 0.803, 'std': 0.012}  \n",
       "weighted avg  {'mean': 0.903, 'std': 0.004}  \n",
       "macro_wo_O    {'mean': 0.777, 'std': 0.014}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Multiclass results:')\n",
    "# dict to dataframe\n",
    "multiclass_results = pd.DataFrame(multiclass_results)\n",
    "multiclass_results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh-crf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
